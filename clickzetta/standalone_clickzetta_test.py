#!/usr/bin/env python3
"""
Clickzetta ç‹¬ç«‹æµ‹è¯•è„šæœ¬

æ­¤è„šæœ¬ç‹¬ç«‹æµ‹è¯• Clickzetta è¿æ¥å™¨çš„åŸºç¡€åŠŸèƒ½ï¼Œä¸ä¾èµ– Dify æ¡†æ¶ã€‚
ç”¨äºéªŒè¯ Clickzetta é›†æˆçš„æ ¸å¿ƒåŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚

è¿è¡Œè¦æ±‚:
- è®¾ç½®æ­£ç¡®çš„ç¯å¢ƒå˜é‡
- å®‰è£… clickzetta-connector-python
- ç¡®ä¿èƒ½è®¿é—® Clickzetta æœåŠ¡

ä½œè€…: Claude Code Assistant
æ—¥æœŸ: 2025-07-17
"""

import json
import logging
import os
import random
import string
import threading
import time
import uuid
from typing import List, Dict, Any

try:
    import clickzetta
except ImportError:
    print("âŒ é”™è¯¯: è¯·å®‰è£… clickzetta-connector-python")
    print("   pip install clickzetta-connector-python>=0.8.102")
    exit(1)

try:
    import numpy as np
except ImportError:
    print("âŒ é”™è¯¯: è¯·å®‰è£… numpy")
    print("   pip install numpy")
    exit(1)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class ClickzettaStandaloneTest:
    """Clickzetta ç‹¬ç«‹æµ‹è¯•ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ"""
        self.connection = None
        self.test_table = f"test_vectors_{int(time.time())}"
        self.test_schema = os.getenv("CLICKZETTA_SCHEMA", "dify")
        self.results = {}
        
        # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
        self.config = {
            "username": os.getenv("CLICKZETTA_USERNAME"),
            "password": os.getenv("CLICKZETTA_PASSWORD"),
            "instance": os.getenv("CLICKZETTA_INSTANCE"),
            "service": os.getenv("CLICKZETTA_SERVICE", "api.clickzetta.com"),
            "workspace": os.getenv("CLICKZETTA_WORKSPACE", "quick_start"),
            "vcluster": os.getenv("CLICKZETTA_VCLUSTER", "default_ap"),
            "schema": self.test_schema
        }
        
        # éªŒè¯å¿…éœ€çš„é…ç½®
        required_keys = ["username", "password", "instance", "service", "workspace", "vcluster"]
        missing_keys = [key for key in required_keys if not self.config.get(key)]
        if missing_keys:
            raise ValueError(f"ç¼ºå°‘å¿…éœ€çš„ç¯å¢ƒå˜é‡: {missing_keys}")
    
    def connect(self) -> bool:
        """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
        try:
            print("ğŸ”Œ æ­£åœ¨è¿æ¥ Clickzetta...")
            self.connection = clickzetta.connect(
                username=self.config["username"],
                password=self.config["password"],
                instance=self.config["instance"],
                service=self.config["service"],
                workspace=self.config["workspace"],
                vcluster=self.config["vcluster"],
                schema=self.config["schema"]
            )
            print("âœ… è¿æ¥æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ è¿æ¥å¤±è´¥: {e}")
            return False
    
    def test_table_operations(self) -> bool:
        """æµ‹è¯•è¡¨æ“ä½œ"""
        print("\nğŸ§ª æµ‹è¯•è¡¨æ“ä½œ...")
        
        try:
            with self.connection.cursor() as cursor:
                # åˆ›å»ºæµ‹è¯•è¡¨
                create_sql = f"""
                CREATE TABLE IF NOT EXISTS {self.test_schema}.{self.test_table} (
                    id STRING NOT NULL,
                    content STRING NOT NULL,
                    metadata JSON,
                    embedding VECTOR(FLOAT, 1536) NOT NULL,
                    PRIMARY KEY (id)
                )
                """
                cursor.execute(create_sql)
                print(f"âœ… è¡¨åˆ›å»ºæˆåŠŸ: {self.test_table}")
                
                # å‡†å¤‡æµ‹è¯•æ•°æ®
                test_data = []
                for i in range(5):
                    doc_id = str(uuid.uuid4())
                    content = f"æµ‹è¯•æ–‡æ¡£ {i+1}: è¿™æ˜¯ä¸€ä¸ªç”¨äºæµ‹è¯•å‘é‡æœç´¢çš„ç¤ºä¾‹æ–‡æ¡£ã€‚"
                    metadata = {
                        "doc_id": doc_id,
                        "document_id": f"doc_{i+1}",
                        "source": "test",
                        "created_at": time.time()
                    }
                    # ç”Ÿæˆéšæœºå‘é‡
                    embedding = np.random.random(1536).tolist()
                    test_data.append((doc_id, content, json.dumps(metadata), embedding))
                
                # æ‰¹é‡æ’å…¥æ•°æ®
                start_time = time.time()
                values = []
                for doc_id, content, metadata_json, embedding in test_data:
                    embedding_str = f"VECTOR({','.join(map(str, embedding))})"
                    escaped_content = content.replace("'", "''")
                    values.append(f"('{doc_id}', '{escaped_content}', "
                                f"JSON '{metadata_json}', {embedding_str})")
                
                insert_sql = f"""
                INSERT INTO {self.test_schema}.{self.test_table}
                (id, content, metadata, embedding)
                VALUES {','.join(values)}
                """
                cursor.execute(insert_sql)
                insert_time = time.time() - start_time
                
                print(f"âœ… æ•°æ®æ’å…¥æˆåŠŸ: {len(test_data)} æ¡è®°å½•ï¼Œè€—æ—¶ {insert_time:.3f}ç§’")
                
                # éªŒè¯æ•°æ®
                cursor.execute(f"SELECT COUNT(*) FROM {self.test_schema}.{self.test_table}")
                count = cursor.fetchone()[0]
                print(f"âœ… æ•°æ®æŸ¥è¯¢æˆåŠŸ: è¡¨ä¸­å…±æœ‰ {count} æ¡è®°å½•")
                
                self.results["table_operations"] = True
                return True
                
        except Exception as e:
            print(f"âŒ è¡¨æ“ä½œæµ‹è¯•å¤±è´¥: {e}")
            self.results["table_operations"] = False
            return False
    
    def test_vector_operations(self) -> bool:
        """æµ‹è¯•å‘é‡æ“ä½œ"""
        print("\nğŸ§ª æµ‹è¯•å‘é‡æ“ä½œ...")
        
        try:
            with self.connection.cursor() as cursor:
                # åˆ›å»ºå‘é‡ç´¢å¼•
                index_name = f"idx_{self.test_table}_vector"
                index_sql = f"""
                CREATE VECTOR INDEX IF NOT EXISTS {index_name}
                ON TABLE {self.test_schema}.{self.test_table}(embedding)
                PROPERTIES (
                    "distance.function" = "cosine_distance",
                    "scalar.type" = "f32",
                    "m" = "16",
                    "ef.construction" = "128"
                )
                """
                cursor.execute(index_sql)
                print("âœ… å‘é‡ç´¢å¼•åˆ›å»ºæˆåŠŸ")
                
                # æµ‹è¯•å‘é‡æœç´¢
                query_vector = np.random.random(1536).tolist()
                search_sql = f"""
                SELECT id, content, metadata,
                       COSINE_DISTANCE(embedding, VECTOR({','.join(map(str, query_vector))})) AS distance
                FROM {self.test_schema}.{self.test_table}
                ORDER BY distance
                LIMIT 3
                """
                
                start_time = time.time()
                cursor.execute(search_sql)
                results = cursor.fetchall()
                search_time = time.time() - start_time
                
                print(f"âœ… å‘é‡æœç´¢æˆåŠŸ: è¿”å› {len(results)} ä¸ªç»“æœï¼Œè€—æ—¶ {search_time*1000:.0f}ms")
                
                # éªŒè¯ç»“æœ
                for i, row in enumerate(results):
                    metadata = json.loads(row[2]) if row[2] else {}
                    distance = row[3]
                    print(f"   ç»“æœ {i+1}: è·ç¦»={distance:.4f}, æ–‡æ¡£={metadata.get('document_id', 'unknown')}")
                
                self.results["vector_operations"] = True
                return True
                
        except Exception as e:
            print(f"âŒ å‘é‡æ“ä½œæµ‹è¯•å¤±è´¥: {e}")
            self.results["vector_operations"] = False
            return False
    
    def test_concurrent_writes(self) -> bool:
        """æµ‹è¯•å¹¶å‘å†™å…¥"""
        print("\nğŸ§ª æµ‹è¯•å¹¶å‘å†™å…¥...")
        
        def worker_thread(thread_id: int, doc_count: int) -> Dict[str, Any]:
            """å·¥ä½œçº¿ç¨‹å‡½æ•°"""
            try:
                # æ¯ä¸ªçº¿ç¨‹ä½¿ç”¨ç‹¬ç«‹è¿æ¥
                worker_connection = clickzetta.connect(
                    username=self.config["username"],
                    password=self.config["password"],
                    instance=self.config["instance"],
                    service=self.config["service"],
                    workspace=self.config["workspace"],
                    vcluster=self.config["vcluster"],
                    schema=self.config["schema"]
                )
                
                start_time = time.time()
                successful_inserts = 0
                
                with worker_connection.cursor() as cursor:
                    for i in range(doc_count):
                        try:
                            doc_id = f"thread_{thread_id}_doc_{i}_{uuid.uuid4()}"
                            content = f"çº¿ç¨‹ {thread_id} æ–‡æ¡£ {i+1}: å¹¶å‘æµ‹è¯•å†…å®¹"
                            metadata = {
                                "thread_id": thread_id,
                                "doc_index": i,
                                "timestamp": time.time()
                            }
                            embedding = np.random.random(1536).tolist()
                            
                            embedding_str = f"VECTOR({','.join(map(str, embedding))})"
                            insert_sql = f"""
                            INSERT INTO {self.test_schema}.{self.test_table}
                            (id, content, metadata, embedding)
                            VALUES ('{doc_id}', '{content}', JSON '{json.dumps(metadata)}', {embedding_str})
                            """
                            cursor.execute(insert_sql)
                            successful_inserts += 1
                            
                            # çŸ­æš‚å»¶è¿Ÿæ¨¡æ‹ŸçœŸå®åœºæ™¯
                            time.sleep(0.05)
                            
                        except Exception as e:
                            logger.warning(f"çº¿ç¨‹ {thread_id} æ’å…¥å¤±è´¥: {e}")
                
                elapsed_time = time.time() - start_time
                return {
                    "thread_id": thread_id,
                    "successful_inserts": successful_inserts,
                    "elapsed_time": elapsed_time,
                    "rate": successful_inserts / elapsed_time if elapsed_time > 0 else 0
                }
                
            except Exception as e:
                logger.error(f"çº¿ç¨‹ {thread_id} æ‰§è¡Œå¤±è´¥: {e}")
                return {
                    "thread_id": thread_id,
                    "successful_inserts": 0,
                    "elapsed_time": 0,
                    "rate": 0,
                    "error": str(e)
                }
        
        try:
            # å¯åŠ¨å¤šä¸ªå·¥ä½œçº¿ç¨‹
            num_threads = 3
            docs_per_thread = 15
            threads = []
            results = []
            
            print(f"å¯åŠ¨ {num_threads} ä¸ªå¹¶å‘å·¥ä½œçº¿ç¨‹...")
            start_time = time.time()
            
            # åˆ›å»ºå¹¶å¯åŠ¨çº¿ç¨‹
            for i in range(num_threads):
                thread = threading.Thread(
                    target=lambda tid=i: results.append(worker_thread(tid, docs_per_thread))
                )
                threads.append(thread)
                thread.start()
            
            # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
            for thread in threads:
                thread.join()
            
            total_time = time.time() - start_time
            
            # ç»Ÿè®¡ç»“æœ
            total_docs = sum(r.get("successful_inserts", 0) for r in results)
            successful_threads = len([r for r in results if r.get("successful_inserts", 0) > 0])
            overall_rate = total_docs / total_time if total_time > 0 else 0
            
            print(f"âœ… å¹¶å‘å†™å…¥æµ‹è¯•å®Œæˆ:")
            print(f"  - æ€»è€—æ—¶: {total_time:.2f} ç§’")
            print(f"  - æˆåŠŸçº¿ç¨‹: {successful_threads}/{num_threads}")
            print(f"  - æ€»æ–‡æ¡£æ•°: {total_docs}")
            print(f"  - æ•´ä½“é€Ÿç‡: {overall_rate:.1f} docs/sec")
            
            # è¯¦ç»†ç»“æœ
            for result in results:
                if "error" in result:
                    print(f"  - çº¿ç¨‹ {result['thread_id']}: å¤±è´¥ - {result['error']}")
                else:
                    print(f"  - çº¿ç¨‹ {result['thread_id']}: {result['successful_inserts']} æ–‡æ¡£, "
                          f"{result['rate']:.1f} docs/sec")
            
            self.results["concurrent_writes"] = successful_threads >= num_threads * 0.8  # 80% æˆåŠŸç‡
            return self.results["concurrent_writes"]
            
        except Exception as e:
            print(f"âŒ å¹¶å‘å†™å…¥æµ‹è¯•å¤±è´¥: {e}")
            self.results["concurrent_writes"] = False
            return False
    
    def cleanup(self) -> None:
        """æ¸…ç†æµ‹è¯•æ•°æ®"""
        try:
            if self.connection:
                with self.connection.cursor() as cursor:
                    cursor.execute(f"DROP TABLE IF EXISTS {self.test_schema}.{self.test_table}")
                print("âœ… æ¸…ç†å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†è­¦å‘Š: {e}")
    
    def run_all_tests(self) -> None:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ Clickzetta ç‹¬ç«‹æµ‹è¯•å¼€å§‹")
        print(f"ğŸ“‹ æµ‹è¯•é…ç½®:")
        print(f"  - æœåŠ¡: {self.config['service']}")
        print(f"  - å®ä¾‹: {self.config['instance']}")
        print(f"  - å·¥ä½œç©ºé—´: {self.config['workspace']}")
        print(f"  - æ¨¡å¼: {self.config['schema']}")
        print(f"  - æµ‹è¯•è¡¨: {self.test_table}")
        print()
        
        try:
            # 1. è¿æ¥æµ‹è¯•
            if not self.connect():
                return
            
            # 2. è¡¨æ“ä½œæµ‹è¯•
            self.test_table_operations()
            
            # 3. å‘é‡æ“ä½œæµ‹è¯•
            self.test_vector_operations()
            
            # 4. å¹¶å‘å†™å…¥æµ‹è¯•
            self.test_concurrent_writes()
            
            # 5. ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
            self.generate_report()
            
        finally:
            # æ¸…ç†
            self.cleanup()
    
    def generate_report(self) -> None:
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("\nğŸ“Š æµ‹è¯•æŠ¥å‘Š:")
        
        total_tests = len(self.results)
        passed_tests = sum(1 for passed in self.results.values() if passed)
        
        for test_name, passed in self.results.items():
            status = "âœ… é€šè¿‡" if passed else "âŒ å¤±è´¥"
            print(f"  - {test_name}: {status}")
        
        success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
        print(f"\nğŸ¯ æ€»ä½“ç»“æœ: {passed_tests}/{total_tests} é€šè¿‡ ({success_rate:.1f}%)")
        
        if success_rate >= 80:
            print("ğŸ‰ æµ‹è¯•æ€»ä½“æˆåŠŸï¼Clickzetta é›†æˆå‡†å¤‡å°±ç»ªã€‚")
        else:
            print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•ã€‚")


def main():
    """ä¸»å‡½æ•°"""
    try:
        test = ClickzettaStandaloneTest()
        test.run_all_tests()
    except KeyboardInterrupt:
        print("\nğŸ›‘ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")


if __name__ == "__main__":
    main()