app:
  description: 'Workflow with LLM node for testing auto-mock'
  icon: ðŸ¤–
  icon_background: '#FFEAD5'
  mode: workflow
  name: llm-simple
  use_icon_as_answer_icon: false
dependencies: []
kind: app
version: 0.3.1
workflow:
  conversation_variables: []
  environment_variables: []
  features:
    file_upload:
      enabled: false
    opening_statement: ''
    retriever_resource:
      enabled: false
    sensitive_word_avoidance:
      enabled: false
    speech_to_text:
      enabled: false
    suggested_questions: []
    suggested_questions_after_answer:
      enabled: false
    text_to_speech:
      enabled: false
  graph:
    edges:
    - data:
        isInIteration: false
        isInLoop: false
        sourceType: start
        targetType: llm
      id: start-to-llm
      source: 'start_node'
      sourceHandle: source
      target: 'llm_node'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        isInLoop: false
        sourceType: llm
        targetType: end
      id: llm-to-end
      source: 'llm_node'
      sourceHandle: source
      target: 'end_node'
      targetHandle: target
      type: custom
      zIndex: 0
    nodes:
    - data:
        desc: ''
        selected: false
        title: Start
        type: start
        variables:
        - label: query
          max_length: null
          options: []
          required: true
          type: text-input
          variable: query
      height: 90
      id: 'start_node'
      position:
        x: 30
        y: 227
      positionAbsolute:
        x: 30
        y: 227
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        desc: 'LLM Node for testing'
        title: LLM
        type: llm
        model:
          provider: openai
          name: gpt-3.5-turbo
          mode: chat
        prompt_template:
          - role: system
            text: You are a helpful assistant.
          - role: user
            text: '{{#start_node.query#}}'
        vision:
          enabled: false
          configs:
            variable_selector: []
        memory:
          enabled: false
          window:
            enabled: false
            size: 50
        context:
          enabled: false
          variable_selector: []
        structured_output:
          enabled: false
        retry_config:
          enabled: false
          max_retries: 1
          retry_interval: 1000
          exponential_backoff:
            enabled: false
            multiplier: 2
            max_interval: 10000
      height: 90
      id: 'llm_node'
      position:
        x: 334
        y: 227
      positionAbsolute:
        x: 334
        y: 227
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        desc: ''
        outputs:
        - value_selector:
          - 'llm_node'
          - text
          value_type: string
          variable: answer
        selected: false
        title: End
        type: end
      height: 90
      id: 'end_node'
      position:
        x: 638
        y: 227
      positionAbsolute:
        x: 638
        y: 227
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    viewport:
      x: 0
      y: 0
      zoom: 0.7