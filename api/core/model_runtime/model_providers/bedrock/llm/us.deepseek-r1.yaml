model: us.deepseek.r1-v1:0
label:
  en_US: DeepSeek-R1(US.Cross Region Inference)
icon: icon_s_en.svg
model_type: llm
features:
  - agent-thought
  - vision
  - tool-call
  - stream-tool-call
model_properties:
  mode: chat
  context_size: 32768
parameter_rules:
  - name: max_tokens
    use_template: max_tokens
    required: true
    label:
      zh_Hans: 最大token数
      en_US: Max Tokens
    type: int
    default: 8192
    min: 1
    max: 128000
    help:
      zh_Hans: 停止前生成的最大令牌数。
      en_US: The maximum number of tokens to generate before stopping.
  - name: temperature
    use_template: temperature
    required: false
    label:
      zh_Hans: 模型温度
      en_US: Model Temperature
    type: float
    default: 1
    min: 0.0
    max: 1.0
    help:
      zh_Hans: 生成内容的随机性。当推理功能启用时，该值将被固定为1。
      en_US: The amount of randomness injected into the response. When reasoning is enabled, this value will be fixed to 1.
  - name: top_p
    show_on:
      - variable: reasoning_type
        value: disabled
    use_template: top_p
    label:
      zh_Hans: Top P
      en_US: Top P
    required: false
    type: float
    default: 0.999
    min: 0.000
    max: 1.000
    help:
      zh_Hans: 在核采样中的概率阈值。当推理功能启用时，该参数将被禁用。
      en_US: The probability threshold in nucleus sampling. When reasoning is enabled, this parameter will be disabled.
  - name: response_format
    use_template: response_format
pricing:
  input: '0.001'
  output: '0.005'
  unit: '0.001'
  currency: USD