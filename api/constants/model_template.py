import json

from models.model import AppModelConfig, App

model_templates = {
    # completion default mode
    'completion_default': {
        'app': {
            'mode': 'completion',
            'enable_site': True,
            'enable_api': True,
            'is_demo': False,
            'api_rpm': 0,
            'api_rph': 0,
            'status': 'normal'
        },
        'model_config': {
            'provider': 'openai',
            'model_id': 'text-davinci-003',
            'configs': {
                'prompt_template': '',
                'prompt_variables': [],
                'completion_params': {
                    'max_token': 512,
                    'temperature': 1,
                    'top_p': 1,
                    'presence_penalty': 0,
                    'frequency_penalty': 0,
                }
            },
            'model': json.dumps({
                "provider": "openai",
                "name": "text-davinci-003",
                "completion_params": {
                    "max_tokens": 512,
                    "temperature": 1,
                    "top_p": 1,
                    "presence_penalty": 0,
                    "frequency_penalty": 0
                }
            }),
            'user_input_form': json.dumps([
                {
                    "paragraph": {
                        "label": "Query",
                        "variable": "query",
                        "required": True,
                        "default": ""
                    }
                }
            ]),
            'pre_prompt': '{{query}}'
        }
    },

    # chat default mode
    'chat_default': {
        'app': {
            'mode': 'chat',
            'enable_site': True,
            'enable_api': True,
            'is_demo': False,
            'api_rpm': 0,
            'api_rph': 0,
            'status': 'normal'
        },
        'model_config': {
            'provider': 'openai',
            'model_id': 'gpt-3.5-turbo',
            'configs': {
                'prompt_template': '',
                'prompt_variables': [],
                'completion_params': {
                    'max_token': 512,
                    'temperature': 1,
                    'top_p': 1,
                    'presence_penalty': 0,
                    'frequency_penalty': 0,
                }
            },
            'model': json.dumps({
                "provider": "openai",
                "name": "gpt-3.5-turbo",
                "completion_params": {
                    "max_tokens": 512,
                    "temperature": 1,
                    "top_p": 1,
                    "presence_penalty": 0,
                    "frequency_penalty": 0
                }
            })
        }
    },
}


demo_model_templates = {
    'en-US': [
        {
            'name': 'Translation Assistant',
            'icon': '',
            'icon_background': '',
            'description': 'A multilingual translator that provides translation capabilities in multiple languages, translating user input into the language they need.',
            'mode': 'completion',
            'model_config': AppModelConfig(
                provider='openai',
                model_id='text-davinci-003',
                configs={
                    'prompt_template': "Please translate the following text into {{target_language}}:\n",
                    'prompt_variables': [
                        {
                            "key": "target_language",
                            "name": "Target Language",
                            "description": "The language you want to translate into.",
                            "type": "select",
                            "default": "Chinese",
                            'options': [
                                'Chinese',
                                'English',
                                'Japanese',
                                'French',
                                'Russian',
                                'German',
                                'Spanish',
                                'Korean',
                                'Italian',
                            ]
                        }
                    ],
                    'completion_params': {
                        'max_token': 1000,
                        'temperature': 0,
                        'top_p': 0,
                        'presence_penalty': 0.1,
                        'frequency_penalty': 0.1,
                    }
                },
                opening_statement='',
                suggested_questions=None,
                pre_prompt="Please translate the following text into {{target_language}}:\n",
                model=json.dumps({
                    "provider": "openai",
                    "name": "text-davinci-003",
                    "completion_params": {
                        "max_tokens": 1000,
                        "temperature": 0,
                        "top_p": 0,
                        "presence_penalty": 0.1,
                        "frequency_penalty": 0.1
                    }
                }),
                user_input_form=json.dumps([
                    {
                        "select": {
                            "label": "Target Language",
                            "variable": "target_language",
                            "description": "The language you want to translate into.",
                            "default": "Chinese",
                            "required": True,
                            'options': [
                                'Chinese',
                                'English',
                                'Japanese',
                                'French',
                                'Russian',
                                'German',
                                'Spanish',
                                'Korean',
                                'Italian',
                            ]
                        }
                    }
                ])
            )
        },
        {
            'name': 'AI Front-end Interviewer',
            'icon': '',
            'icon_background': '',
            'description': 'A simulated front-end interviewer that tests the skill level of front-end development through questioning.',
            'mode': 'chat',
            'model_config': AppModelConfig(
                provider='openai',
                model_id='gpt-3.5-turbo',
                configs={
                    'introduction': 'Hi, welcome to our interview. I am the interviewer for this technology company, and I will test your web front-end development skills. Next, I will ask you some technical questions. Please answer them as thoroughly as possible. ',
                    'prompt_template': "You will play the role of an interviewer for a technology company, examining the user's web front-end development skills and posing 5-10 sharp technical questions.\n\nPlease note:\n- Only ask one question at a time.\n- After the user answers a question, ask the next question directly, without trying to correct any mistakes made by the candidate.\n- If you think the user has not answered correctly for several consecutive questions, ask fewer questions.\n- After asking the last question, you can ask this question: Why did you leave your last job? After the user answers this question, please express your understanding and support.\n",
                    'prompt_variables': [],
                    'completion_params': {
                        'max_token': 300,
                        'temperature': 0.8,
                        'top_p': 0.9,
                        'presence_penalty': 0.1,
                        'frequency_penalty': 0.1,
                    }
                },
                opening_statement='Hi, welcome to our interview. I am the interviewer for this technology company, and I will test your web front-end development skills. Next, I will ask you some technical questions. Please answer them as thoroughly as possible. ',
                suggested_questions=None,
                pre_prompt="You will play the role of an interviewer for a technology company, examining the user's web front-end development skills and posing 5-10 sharp technical questions.\n\nPlease note:\n- Only ask one question at a time.\n- After the user answers a question, ask the next question directly, without trying to correct any mistakes made by the candidate.\n- If you think the user has not answered correctly for several consecutive questions, ask fewer questions.\n- After asking the last question, you can ask this question: Why did you leave your last job? After the user answers this question, please express your understanding and support.\n",
                model=json.dumps({
                    "provider": "openai",
                    "name": "gpt-3.5-turbo",
                    "completion_params": {
                        "max_tokens": 300,
                        "temperature": 0.8,
                        "top_p": 0.9,
                        "presence_penalty": 0.1,
                        "frequency_penalty": 0.1
                    }
                }),
                user_input_form=None
            )
        },
        {
            'name': 'AI Graph Generator',
            'icon': '',
            'icon_background': '',
            'description': 'According to the user\'s stated requirements, mermaid code blocks are generated by AI, and the code blocks are rendered into corresponding SVG vector drawings.',
            'mode': 'chat',
            'model_config': AppModelConfig(
                provider='openai',
                model_id='gpt-3.5-turbo',
                configs={
                    'introduction': 'Warm reminder: Click ğŸ‘ for correct reply and ğŸ‘ for inaccurate reply, which will help me further improve myself and greatly improve the accuracy of reply to similar questions. Hello, please tell me about your image generation needs: ',
                    'prompt_template': "You will play as a mermaid graphics generator, generating code blocks that conform to mermaid format requirements based on user scenario descriptions. \n\n[Note]\n\n- Output mermaid code blocks only, no other explanation. \nLet\'s think step by step.\n",
                    'prompt_variables': [],
                    'completion_params': {
                        'max_token': 300,
                        'temperature': 0.8,
                        'top_p': 0.9,
                        'presence_penalty': 0.1,
                        'frequency_penalty': 0.1,
                    }
                },
                opening_statement='Warm reminder: Click ğŸ‘ for correct reply and ğŸ‘ for inaccurate reply, which will help me further improve myself and greatly improve the accuracy of reply to similar questions. Hello, please tell me about your image generation needs: ',
                suggested_questions=None,
                pre_prompt="You will play as a mermaid graphics generator, generating code blocks that conform to mermaid format requirements based on user scenario descriptions. \n\n[Note]\n\n- Output mermaid code blocks only, no other explanation. \nLet\'s think step by step.\n",
                model=json.dumps({
                    "provider": "openai",
                    "name": "gpt-3.5-turbo",
                    "completion_params": {
                        "max_tokens": 300,
                        "temperature": 0.8,
                        "top_p": 0.9,
                        "presence_penalty": 0.1,
                        "frequency_penalty": 0.1
                    }
                }),
                user_input_form=None
            )
        }
    ],

    'zh-Hans': [
        {
            'name': 'ç¿»è¯‘åŠ©æ‰‹',
            'icon': '',
            'icon_background': '',
            'description': 'ä¸€ä¸ªå¤šè¯­è¨€ç¿»è¯‘å™¨ï¼Œæä¾›å¤šç§è¯­è¨€ç¿»è¯‘èƒ½åŠ›ï¼Œå°†ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬ç¿»è¯‘æˆä»–ä»¬éœ€è¦çš„è¯­è¨€ã€‚',
            'mode': 'completion',
            'model_config': AppModelConfig(
                provider='openai',
                model_id='text-davinci-003',
                configs={
                    'prompt_template': "è¯·å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘ä¸º{{target_language}}:\n",
                    'prompt_variables': [
                        {
                            "key": "target_language",
                            "name": "ç›®æ ‡è¯­è¨€",
                            "description": "ç¿»è¯‘çš„ç›®æ ‡è¯­è¨€",
                            "type": "select",
                            "default": "ä¸­æ–‡",
                            "options": [
                                "ä¸­æ–‡",
                                "è‹±æ–‡",
                                "æ—¥è¯­",
                                "æ³•è¯­",
                                "ä¿„è¯­",
                                "å¾·è¯­",
                                "è¥¿ç­ç‰™è¯­",
                                "éŸ©è¯­",
                                "æ„å¤§åˆ©è¯­",
                            ]
                        }
                    ],
                    'completion_params': {
                        'max_token': 1000,
                        'temperature': 0,
                        'top_p': 0,
                        'presence_penalty': 0.1,
                        'frequency_penalty': 0.1,
                    }
                },
                opening_statement='',
                suggested_questions=None,
                pre_prompt="è¯·å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘ä¸º{{target_language}}:\n",
                model=json.dumps({
                    "provider": "openai",
                    "name": "text-davinci-003",
                    "completion_params": {
                        "max_tokens": 1000,
                        "temperature": 0,
                        "top_p": 0,
                        "presence_penalty": 0.1,
                        "frequency_penalty": 0.1
                    }
                }),
                user_input_form=json.dumps([
                    {
                        "select": {
                            "label": "ç›®æ ‡è¯­è¨€",
                            "variable": "target_language",
                            "description": "ç¿»è¯‘çš„ç›®æ ‡è¯­è¨€",
                            "default": "ä¸­æ–‡",
                            "required": True,
                            'options': [
                                "ä¸­æ–‡",
                                "è‹±æ–‡",
                                "æ—¥è¯­",
                                "æ³•è¯­",
                                "ä¿„è¯­",
                                "å¾·è¯­",
                                "è¥¿ç­ç‰™è¯­",
                                "éŸ©è¯­",
                                "æ„å¤§åˆ©è¯­",
                            ]
                        }
                    }
                ])
            )
        },
        {
            'name': 'AI å‰ç«¯é¢è¯•å®˜',
            'icon': '',
            'icon_background': '',
            'description': 'ä¸€ä¸ªæ¨¡æ‹Ÿçš„å‰ç«¯é¢è¯•å®˜ï¼Œé€šè¿‡æé—®çš„æ–¹å¼å¯¹å‰ç«¯å¼€å‘çš„æŠ€èƒ½æ°´å¹³è¿›è¡Œæ£€éªŒã€‚',
            'mode': 'chat',
            'model_config': AppModelConfig(
                provider='openai',
                model_id='gpt-3.5-turbo',
                configs={
                    'introduction': 'ä½ å¥½ï¼Œæ¬¢è¿æ¥å‚åŠ æˆ‘ä»¬çš„é¢è¯•ï¼Œæˆ‘æ˜¯è¿™å®¶ç§‘æŠ€å…¬å¸çš„é¢è¯•å®˜ï¼Œæˆ‘å°†è€ƒå¯Ÿä½ çš„ Web å‰ç«¯å¼€å‘æŠ€èƒ½ã€‚æ¥ä¸‹æ¥æˆ‘ä¼šå‘æ‚¨æå‡ºä¸€äº›æŠ€æœ¯é—®é¢˜ï¼Œè¯·æ‚¨å°½å¯èƒ½è¯¦å°½åœ°å›ç­”ã€‚',
                    'prompt_template': "ä½ å°†æ‰®æ¼”ä¸€ä¸ªç§‘æŠ€å…¬å¸çš„é¢è¯•å®˜ï¼Œè€ƒå¯Ÿç”¨æˆ·ä½œä¸ºå€™é€‰äººçš„ Web å‰ç«¯å¼€å‘æ°´å¹³ï¼Œæå‡º 5-10 ä¸ªçŠ€åˆ©çš„æŠ€æœ¯é—®é¢˜ã€‚\n\nè¯·æ³¨æ„ï¼š\n- æ¯æ¬¡åªé—®ä¸€ä¸ªé—®é¢˜\n- ç”¨æˆ·å›ç­”é—®é¢˜åè¯·ç›´æ¥é—®ä¸‹ä¸€ä¸ªé—®é¢˜ï¼Œè€Œä¸è¦è¯•å›¾çº æ­£å€™é€‰äººçš„é”™è¯¯ï¼›\n- å¦‚æœä½ è®¤ä¸ºç”¨æˆ·è¿ç»­å‡ æ¬¡å›ç­”çš„éƒ½ä¸å¯¹ï¼Œå°±å°‘é—®ä¸€ç‚¹ï¼›\n- é—®å®Œæœ€åä¸€ä¸ªé—®é¢˜åï¼Œä½ å¯ä»¥é—®è¿™æ ·ä¸€ä¸ªé—®é¢˜ï¼šä¸Šä¸€ä»½å·¥ä½œä¸ºä»€ä¹ˆç¦»èŒï¼Ÿç”¨æˆ·å›ç­”è¯¥é—®é¢˜åï¼Œè¯·è¡¨ç¤ºç†è§£ä¸æ”¯æŒã€‚\n",
                    'prompt_variables': [],
                    'completion_params': {
                        'max_token': 300,
                        'temperature': 0.8,
                        'top_p': 0.9,
                        'presence_penalty': 0.1,
                        'frequency_penalty': 0.1,
                    }
                },
                opening_statement='ä½ å¥½ï¼Œæ¬¢è¿æ¥å‚åŠ æˆ‘ä»¬çš„é¢è¯•ï¼Œæˆ‘æ˜¯è¿™å®¶ç§‘æŠ€å…¬å¸çš„é¢è¯•å®˜ï¼Œæˆ‘å°†è€ƒå¯Ÿä½ çš„ Web å‰ç«¯å¼€å‘æŠ€èƒ½ã€‚æ¥ä¸‹æ¥æˆ‘ä¼šå‘æ‚¨æå‡ºä¸€äº›æŠ€æœ¯é—®é¢˜ï¼Œè¯·æ‚¨å°½å¯èƒ½è¯¦å°½åœ°å›ç­”ã€‚',
                suggested_questions=None,
                pre_prompt="ä½ å°†æ‰®æ¼”ä¸€ä¸ªç§‘æŠ€å…¬å¸çš„é¢è¯•å®˜ï¼Œè€ƒå¯Ÿç”¨æˆ·ä½œä¸ºå€™é€‰äººçš„ Web å‰ç«¯å¼€å‘æ°´å¹³ï¼Œæå‡º 5-10 ä¸ªçŠ€åˆ©çš„æŠ€æœ¯é—®é¢˜ã€‚\n\nè¯·æ³¨æ„ï¼š\n- æ¯æ¬¡åªé—®ä¸€ä¸ªé—®é¢˜\n- ç”¨æˆ·å›ç­”é—®é¢˜åè¯·ç›´æ¥é—®ä¸‹ä¸€ä¸ªé—®é¢˜ï¼Œè€Œä¸è¦è¯•å›¾çº æ­£å€™é€‰äººçš„é”™è¯¯ï¼›\n- å¦‚æœä½ è®¤ä¸ºç”¨æˆ·è¿ç»­å‡ æ¬¡å›ç­”çš„éƒ½ä¸å¯¹ï¼Œå°±å°‘é—®ä¸€ç‚¹ï¼›\n- é—®å®Œæœ€åä¸€ä¸ªé—®é¢˜åï¼Œä½ å¯ä»¥é—®è¿™æ ·ä¸€ä¸ªé—®é¢˜ï¼šä¸Šä¸€ä»½å·¥ä½œä¸ºä»€ä¹ˆç¦»èŒï¼Ÿç”¨æˆ·å›ç­”è¯¥é—®é¢˜åï¼Œè¯·è¡¨ç¤ºç†è§£ä¸æ”¯æŒã€‚\n",
                model=json.dumps({
                    "provider": "openai",
                    "name": "gpt-3.5-turbo",
                    "completion_params": {
                        "max_tokens": 300,
                        "temperature": 0.8,
                        "top_p": 0.9,
                        "presence_penalty": 0.1,
                        "frequency_penalty": 0.1
                    }
                }),
                user_input_form=None
            )
        },
        {
            'name': 'AI å›¾å½¢ç”Ÿæˆå™¨',
            'icon': '',
            'icon_background': '',
            'description': 'æ ¹æ®ç”¨æˆ·é™ˆè¿°éœ€æ±‚åˆ©ç”¨AIç”Ÿæˆmermaidä»£ç å—ï¼Œå°†ä»£ç å—æ¸²æŸ“æˆå¯¹åº”SVGçŸ¢é‡å›¾ã€‚',
            'mode': 'chat',
            'model_config': AppModelConfig(
                provider='openai',
                model_id='gpt-3.5-turbo',
                configs={
                    'introduction': '    æ¸©é¦¨æé†’ï¼šå¯¹æ­£ç¡®çš„å›å¤ç‚¹å‡» ğŸ‘èµåŒã€ä¸å‡†ç¡®çš„å›å¤ç‚¹å‡» ğŸ‘åå¯¹ï¼Œå°†æœ‰åŠ©æˆ‘è¿›ä¸€æ­¥è‡ªæˆ‘å®Œå–„ï¼Œå¤§å¹…æé«˜åŒç±»å‹é—®é¢˜å›å¤çš„å‡†ç¡®æ€§ã€‚\nä½ å¥½ï¼Œè¯·å‘Šè¯‰æˆ‘æ‚¨çš„å›¾åƒç”Ÿæˆéœ€æ±‚ï¼š',
                    'prompt_template': "ä½ å°†æ‰®æ¼”mermaidå›¾å½¢ç”Ÿæˆå™¨ï¼Œæ ¹æ®ç”¨æˆ·åœºæ™¯æè¿°ç”Ÿæˆç¬¦åˆmermaidæ ¼å¼è¦æ±‚çš„ä»£ç å—ã€‚\n\n[æ³¨æ„äº‹é¡¹]\n\n- ä»…è¾“å‡ºmermaidä»£ç å—ï¼Œä¸åšå…¶ä»–è§£é‡Šã€‚\nLet\'s think step by step.\n",
                    'prompt_variables': [],
                    'completion_params': {
                        'max_token': 1024,
                        'temperature': 0.8,
                        'top_p': 0.9,
                        'presence_penalty': 0.1,
                        'frequency_penalty': 0.1,
                    }
                },
                opening_statement='    æ¸©é¦¨æé†’ï¼šå¯¹æ­£ç¡®çš„å›å¤ç‚¹å‡» ğŸ‘èµåŒã€ä¸å‡†ç¡®çš„å›å¤ç‚¹å‡» ğŸ‘åå¯¹ï¼Œå°†æœ‰åŠ©æˆ‘è¿›ä¸€æ­¥è‡ªæˆ‘å®Œå–„ï¼Œå¤§å¹…æé«˜åŒç±»å‹é—®é¢˜å›å¤çš„å‡†ç¡®æ€§ã€‚\nä½ å¥½ï¼Œè¯·å‘Šè¯‰æˆ‘æ‚¨çš„å›¾åƒç”Ÿæˆéœ€æ±‚ï¼š',
                suggested_questions=None,
                pre_prompt="ä½ å°†æ‰®æ¼”mermaidå›¾å½¢ç”Ÿæˆå™¨ï¼Œæ ¹æ®ç”¨æˆ·åœºæ™¯æè¿°ç”Ÿæˆç¬¦åˆmermaidæ ¼å¼è¦æ±‚çš„ä»£ç å—ã€‚\n\n[æ³¨æ„äº‹é¡¹]\n\n- ä»…è¾“å‡ºmermaidä»£ç å—ï¼Œä¸åšå…¶ä»–è§£é‡Šã€‚\nLet\'s think step by step.\n",
                model=json.dumps({
                    "provider": "openai",
                    "name": "gpt-3.5-turbo",
                    "completion_params": {
                        "max_tokens": 1024,
                        "temperature": 0.8,
                        "top_p": 0.9,
                        "presence_penalty": 0.1,
                        "frequency_penalty": 0.1
                    }
                }),
                user_input_form=None
            )
        }
    ],
}
