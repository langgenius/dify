// This file is auto-generated by @hey-api/openapi-ts

export type ChatRequest = {
  /**
   * User Input/Question content.
   */
  query: string
  /**
   * Allows the entry of various variable values defined by the App. Contains key/value pairs. Default {}.
   */
  inputs?: {
    [key: string]: unknown
  }
  /**
   * Mode of response return. `streaming` (recommended) uses SSE. `blocking` returns after completion (may be interrupted for long processes; not supported in Agent Assistant mode). Cloudflare timeout is 100s.
   */
  response_mode?: 'streaming' | 'blocking'
  /**
   * User identifier, unique within the application. **Note**: The Service API does not share conversations created by the WebApp. Conversations created through the API are isolated from those created in the WebApp interface.
   */
  user: string
  /**
   * Conversation ID to continue a conversation. Pass the previous message's conversation_id.
   */
  conversation_id?: string
  /**
   * File list (images) for Vision-capable models.
   */
  files?: Array<InputFileObject>
  /**
   * Auto-generate conversation title. Default `true`. If `false`, use conversation rename API with `auto_generate: true` for async title generation.
   */
  auto_generate_name?: boolean
}

export type InputFileObject = ({
  transfer_method?: 'remote_url'
  url: string
} | {
  transfer_method?: 'local_file'
  upload_file_id: string
}) & {
  /**
   * Supported type: `image`.
   */
  type: 'image'
  /**
   * Transfer method, `remote_url` for image URL / `local_file` for file upload
   */
  transfer_method: 'remote_url' | 'local_file'
  /**
   * Image URL (when the transfer method is `remote_url`)
   */
  url?: string
  /**
   * Uploaded file ID, which must be obtained by uploading through the File Upload API in advance (when the transfer method is `local_file`)
   */
  upload_file_id?: string
}

/**
 * Response object for blocking mode chat completion.
 */
export type ChatCompletionResponse = {
  /**
   * Event type, fixed as `message`.
   */
  event?: string
  /**
   * Task ID for request tracking and stop response API.
   */
  task_id?: string
  /**
   * Unique ID of this response/message event.
   */
  id?: string
  /**
   * Unique message ID.
   */
  message_id?: string
  /**
   * Conversation ID.
   */
  conversation_id?: string
  /**
   * App mode, fixed as `chat`.
   */
  mode?: string
  /**
   * Complete response content.
   */
  answer?: string
  metadata?: {
    usage?: Usage
    retriever_resources?: Array<RetrieverResource>
  }
  /**
   * Message creation timestamp (Unix epoch seconds).
   */
  created_at?: number
}

/**
 * Base schema for Server-Sent Event chunks in streaming mode.
 */
export type ChunkChatEvent = {
  /**
   * The type of event.
   */
  event: 'message' | 'agent_message' | 'tts_message' | 'tts_message_end' | 'agent_thought' | 'message_file' | 'message_end' | 'message_replace' | 'error' | 'ping'
}

export type StreamEventBase = {
  /**
   * Task ID.
   */
  task_id?: string
  /**
   * Unique message ID.
   */
  message_id?: string
  /**
   * Conversation ID.
   */
  conversation_id?: string
  /**
   * Creation timestamp.
   */
  created_at?: number
}

export type StreamEventChatMessage = Omit<ChunkChatEvent, 'event'> & StreamEventBase & {
  /**
   * LLM returned text chunk.
   */
  answer: string
  event: 'message'
}

export type StreamEventChatAgentMessage = Omit<ChunkChatEvent, 'event'> & StreamEventBase & {
  /**
   * LLM returned text chunk (Agent mode).
   */
  answer: string
  event: 'agent_message'
}

export type StreamEventChatTtsMessage = Omit<ChunkChatEvent, 'event'> & StreamEventBase & {
  /**
   * Base64 encoded audio chunk.
   */
  audio: string
  event: 'tts_message'
}

export type StreamEventChatTtsMessageEnd = Omit<ChunkChatEvent, 'event'> & StreamEventBase & {
  /**
   * Empty string for end event.
   */
  audio: string
  event: 'tts_message_end'
}

export type StreamEventChatAgentThought = Omit<ChunkChatEvent, 'event'> & StreamEventBase & {
  /**
   * Agent thought ID.
   */
  id: string
  /**
   * Position of this thought in the sequence for the message.
   */
  position: number
  /**
   * What LLM is thinking.
   */
  thought?: string
  /**
   * Response from tool calls.
   */
  observation?: string
  /**
   * List of tools called, split by ';'.
   */
  tool?: string
  /**
   * Input of tools in JSON format. Example: {"dalle3": {"prompt": "a cute cat"}}.
   */
  tool_input?: string
  /**
   * File IDs of files related to this thought (e.g., generated by a tool).
   */
  message_files?: Array<string>
  event: 'agent_thought'
}

export type StreamEventChatMessageFile = Omit<ChunkChatEvent, 'event'> & {
  /**
   * File unique ID.
   */
  id: string
  /**
   * File type, currently only 'image'.
   */
  type: 'image'
  /**
   * Who this file belongs to, always 'assistant' here.
   */
  belongs_to: 'assistant'
  /**
   * Remote URL of the file.
   */
  url: string
  /**
   * Conversation ID.
   */
  conversation_id: string
  event: 'message_file'
}

export type StreamEventChatMessageEnd = Omit<ChunkChatEvent, 'event'> & StreamEventBase & {
  metadata: {
    usage?: Usage
    retriever_resources?: Array<RetrieverResource>
  }
  event: 'message_end'
}

export type StreamEventChatMessageReplace = Omit<ChunkChatEvent, 'event'> & StreamEventBase & {
  /**
   * Replacement content.
   */
  answer: string
  event: 'message_replace'
}

export type StreamEventChatError = Omit<ChunkChatEvent, 'event'> & StreamEventBase & {
  /**
   * HTTP status code.
   */
  status: number
  /**
   * Error code.
   */
  code: string
  /**
   * Error message.
   */
  message: string
  event: 'error'
}

export type StreamEventChatPing = Omit<ChunkChatEvent, 'event'> & {
  event: 'ping'
  [key: string]: unknown | 'ping'
}

/**
 * Model usage information.
 */
export type Usage = {
  prompt_tokens?: number
  prompt_unit_price?: string
  prompt_price_unit?: string
  prompt_price?: string
  completion_tokens?: number
  completion_unit_price?: string
  completion_price_unit?: string
  completion_price?: string
  total_tokens?: number
  total_price?: string
  currency?: string
  latency?: number
}

/**
 * Citation and Attribution information for a resource.
 */
export type RetrieverResource = {
  /**
   * Position of the resource in the list.
   */
  position?: number
  /**
   * ID of the dataset.
   */
  dataset_id?: string
  /**
   * Name of the dataset.
   */
  dataset_name?: string
  /**
   * ID of the document.
   */
  document_id?: string
  /**
   * Name of the document.
   */
  document_name?: string
  /**
   * ID of the specific segment within the document.
   */
  segment_id?: string
  /**
   * Relevance score of the resource.
   */
  score?: number
  /**
   * Content snippet from the resource.
   */
  content?: string
}

export type FileUploadResponse = {
  id?: string
  name?: string
  size?: number
  extension?: string
  mime_type?: string
  created_by?: string
  created_at?: number
}

export type MessageFeedbackRequest = {
  rating?: 'like' | 'dislike' | null
  user: string
  content?: string
}

export type AppFeedbacksResponse = {
  data?: Array<FeedbackItem>
}

export type FeedbackItem = {
  id?: string
  app_id?: string
  conversation_id?: string
  message_id?: string
  rating?: 'like' | 'dislike' | null
  content?: string
  from_source?: string
  from_end_user_id?: string
  from_account_id?: string | null
  created_at?: string
  updated_at?: string
}

export type SuggestedQuestionsResponse = {
  result?: string
  data?: Array<string>
}

export type ConversationHistoryResponse = {
  limit?: number
  has_more?: boolean
  data?: Array<ConversationMessageItem>
}

export type ConversationMessageItem = {
  id?: string
  conversation_id?: string
  inputs?: {
    [key: string]: unknown
  }
  query?: string
  answer?: string
  message_files?: Array<MessageFileItem>
  feedback?: {
    rating?: 'like' | 'dislike'
  } | null
  retriever_resources?: Array<RetrieverResource>
  agent_thoughts?: Array<AgentThoughtItem>
  created_at?: number
}

export type MessageFileItem = {
  id?: string
  /**
   * File type, e.g., 'image'.
   */
  type?: string
  /**
   * Preview image URL.
   */
  url?: string
  /**
   * Who this file belongs to.
   */
  belongs_to?: 'user' | 'assistant'
}

export type AgentThoughtItem = {
  /**
   * Agent thought ID.
   */
  id?: string
  /**
   * Unique message ID this thought belongs to.
   */
  message_id?: string
  /**
   * Position of this thought.
   */
  position?: number
  /**
   * What LLM is thinking.
   */
  thought?: string
  /**
   * Tools called, split by ';'.
   */
  tool?: string
  /**
   * Input of tools in JSON format.
   */
  tool_input?: string
  /**
   * Response from tool calls.
   */
  observation?: string
  /**
   * File IDs related to this thought (from example, Markdown text says 'message_files').
   */
  files?: Array<string>
  /**
   * Creation timestamp.
   */
  created_at?: number
}

export type ConversationsListResponse = {
  limit?: number
  has_more?: boolean
  data?: Array<ConversationListItem>
}

export type ConversationListItem = {
  id?: string
  name?: string
  inputs?: {
    [key: string]: unknown
  }
  status?: string
  introduction?: string
  created_at?: number
  updated_at?: number
}

export type ConversationRenameRequest = {
  /**
   * (Optional) The name of the conversation. Omit if auto_generate is true.
   */
  name?: string
  /**
   * (Optional) Automatically generate the title. Default false.
   */
  auto_generate?: boolean
  /**
   * The user identifier.
   */
  user: string
}

export type ConversationRenameResponse = ConversationListItem

export type ConversationVariablesResponse = {
  /**
   * Number of items per page.
   */
  limit?: number
  /**
   * Whether there is a next page.
   */
  has_more?: boolean
  data?: Array<ConversationVariableItem>
}

export type ConversationVariableItem = {
  /**
   * Variable ID.
   */
  id?: string
  /**
   * Variable name.
   */
  name?: string
  /**
   * Variable type (string, number, object, json, etc.).
   */
  value_type?: string
  /**
   * Variable value (can be a JSON string for complex types).
   */
  value?: string
  /**
   * Variable description.
   */
  description?: string
  /**
   * Creation timestamp.
   */
  created_at?: number
  /**
   * Last update timestamp.
   */
  updated_at?: number
}

export type AudioToTextRequest = {
  /**
   * Audio file. Supported: mp3, mp4, mpeg, mpga, m4a, wav, webm. Limit: 15MB.
   */
  file: Blob | File
  /**
   * User identifier.
   */
  user: string
}

export type AudioToTextResponse = {
  /**
   * Output text from speech recognition.
   */
  text?: string
}

/**
 * Requires `user`. Provide either `message_id` or `text`.
 */
export type TextToAudioFormRequest = {
  /**
   * Message ID (priority if both text and message_id provided).
   */
  message_id?: string
  /**
   * Speech content.
   */
  text?: string
  /**
   * User identifier.
   */
  user: string
}

export type AppInfoResponse = {
  name?: string
  description?: string
  tags?: Array<string>
}

export type ChatAppParametersResponse = {
  opening_statement?: string
  suggested_questions?: Array<string>
  suggested_questions_after_answer?: {
    enabled?: boolean
  }
  speech_to_text?: {
    enabled?: boolean
  }
  text_to_speech?: {
    enabled?: boolean
    voice?: string
    language?: string
    autoPlay?: 'enabled' | 'disabled'
  }
  retriever_resource?: {
    enabled?: boolean
  }
  annotation_reply?: {
    enabled?: boolean
  }
  user_input_form?: Array<UserInputFormItem>
  file_upload?: {
    image?: {
      enabled?: boolean
      number_limits?: number
      detail?: string
      transfer_methods?: Array<'remote_url' | 'local_file'>
    }
  }
  system_parameters?: {
    file_size_limit?: number
    image_file_size_limit?: number
    audio_file_size_limit?: number
    video_file_size_limit?: number
  }
}

export type UserInputFormItem = TextInputControlWrapper | ParagraphControlWrapper | SelectControlWrapper

export type TextInputControlWrapper = {
  'text-input': TextInputControl
}

export type ParagraphControlWrapper = {
  paragraph: ParagraphControl
}

export type SelectControlWrapper = {
  select: SelectControl
}

export type TextInputControl = {
  label: string
  variable: string
  required: boolean
  default?: string
}

export type ParagraphControl = {
  label: string
  variable: string
  required: boolean
  default?: string
}

export type SelectControl = {
  label: string
  variable: string
  required: boolean
  default?: string
  options: Array<string>
}

export type AppMetaResponse = {
  /**
   * Tool icons. Keys are tool names.
   */
  tool_icons?: {
    [key: string]: string | ToolIconDetail
  }
}

export type ToolIconDetail = {
  /**
   * Background color in hex format.
   */
  background?: string
  /**
   * Emoji content.
   */
  content?: string
}

export type WebAppSettingsResponse = {
  title?: string
  chat_color_theme?: string
  chat_color_theme_inverted?: boolean
  icon_type?: 'emoji' | 'image'
  icon?: string
  icon_background?: string
  icon_url?: string | null
  description?: string
  copyright?: string
  privacy_policy?: string
  custom_disclaimer?: string
  default_language?: string
  show_workflow_steps?: boolean
  use_icon_as_answer_icon?: boolean
}

export type AnnotationListResponse = {
  data?: Array<AnnotationItem>
  has_more?: boolean
  limit?: number
  total?: number
  page?: number
}

export type AnnotationItem = {
  id?: string
  question?: string
  answer?: string
  hit_count?: number
  created_at?: number
}

export type CreateAnnotationRequest = {
  question: string
  answer: string
}

export type UpdateAnnotationRequest = {
  question: string
  answer: string
}

export type InitialAnnotationReplySettingsRequest = {
  /**
   * Specified embedding model provider name (Optional).
   */
  embedding_provider_name?: string
  /**
   * Specified embedding model name (Optional).
   */
  embedding_model_name?: string
  /**
   * Similarity threshold for matching annotated replies.
   */
  score_threshold: number
}

export type InitialAnnotationReplySettingsResponse = {
  job_id?: string
  job_status?: string
}

export type InitialAnnotationReplySettingsStatusResponse = {
  job_id?: string
  job_status?: string
  error_msg?: string | null
}

export type ErrorResponse = {
  status?: number
  code?: string
  message?: string
}
